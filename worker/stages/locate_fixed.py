"""
Locate Stage - Find problematic files using LLM analysis
"""

import os
import logging
from typing import Dict, Any, List
from datetime import datetime

try:
    from ..templates import render_analysis
    from ..llm_client import get_llm_client
except ImportError:
    import sys
    sys.path.append(os.path.dirname(os.path.dirname(__file__)))
    from templates import render_analysis
    from llm_client import get_llm_client

logger = logging.getLogger(__name__)

async def run_locate_stage(job: Dict[str, Any], repo_path: str, api, gitops) -> Dict[str, Any]:
    """
    Run the locate stage - identify files that might contain the bug using LLM analysis
    
    This implementation uses LLM to intelligently analyze the issue and suggest candidate files.
    Falls back to simple heuristics if LLM is unavailable.
    """
    try:
        logger.info("Starting locate stage with LLM analysis")
        
        # Check for demo override first
        demo_files = os.getenv('DEMO_LOCATE_FILES')
        if demo_files:
            candidate_files = [f.strip() for f in demo_files.split(',')]
            logger.info(f"Using demo override files: {candidate_files}")
            
            # Generate simple analysis for demo files
            analysis_content = render_analysis(
                issue_title=job.get('issue_title', 'Unknown Issue'),
                issue_body=job.get('issue_body', ''),
                candidate_files=candidate_files
            )
        else:
            logger.info(f"ğŸ§  Starting LLM-powered analysis for issue: {job.get('issue_title', 'Unknown Issue')}")
            
            # Get repository file list for LLM analysis
            file_list = get_repository_files(repo_path)
            logger.info(f"Found {len(file_list)} files in repository")
            
            # Use LLM to analyze the bug and suggest files
            llm_client = get_llm_client()
            
            try:
                logger.info("ğŸ¤– Calling LLM for bug analysis...")
                bug_analysis = await llm_client.analyze_bug(
                    issue_title=job.get('issue_title', 'Unknown Issue'),
                    issue_body=job.get('issue_body', ''),
                    file_list=file_list
                )
                
                candidate_files = bug_analysis.get('candidate_files', [])
                logger.info(f"ğŸ¯ LLM suggested {len(candidate_files)} candidate files: {candidate_files}")
                
                # Generate enhanced analysis report
                analysis_content = render_analysis_with_llm(
                    issue_title=job.get('issue_title', 'Unknown Issue'),
                    issue_body=job.get('issue_body', ''),
                    candidate_files=candidate_files,
                    llm_analysis=bug_analysis
                )
                
                logger.info(f"âœ… LLM analysis completed successfully")
                
            except Exception as e:
                logger.warning(f"âŒ LLM analysis failed, using heuristics: {e}")
                # Fall back to heuristics
                candidate_files = find_candidate_files(job, repo_path)
                
                analysis_content = render_analysis(
                    issue_title=job.get('issue_title', 'Unknown Issue'),
                    issue_body=job.get('issue_body', ''),
                    candidate_files=candidate_files
                )
        
        # Write analysis file
        await gitops.write_file(repo_path, 'agent/analysis.md', analysis_content)
        await gitops.add_file(repo_path, 'agent/analysis.md')
        await gitops.commit(repo_path, 'chore(agent): add problem analysis')
        await gitops.push(repo_path, job['branch'])
        
        # Store results in job
        job['candidate_files'] = candidate_files
        
        # Enhanced comment for better user feedback
        comment = f"""ğŸ” **ç¬¬1é˜¶æ®µï¼šé—®é¢˜å®šä½åˆ†æå®Œæˆ**

**ğŸ¯ åˆ†æç»“æœ:**
- å€™é€‰é—®é¢˜æ–‡ä»¶: **{len(candidate_files)}ä¸ª**
- åˆ†ææ–¹æ³•: AIæ™ºèƒ½åˆ†æ + å¯å‘å¼åŒ¹é…
- ç½®ä¿¡åº¦: {'ğŸŸ¢ é«˜' if len(candidate_files) <= 5 else 'ğŸŸ¡ ä¸­ç­‰'}

**ğŸ“ è¯†åˆ«å‡ºçš„å…³é”®æ–‡ä»¶:**
{chr(10).join(f'- `{f}` - é«˜åº¦ç›¸å…³' for f in candidate_files[:5])}
{('- ... è¿˜æœ‰æ›´å¤šæ–‡ä»¶ (æŸ¥çœ‹analysis.mdè·å–å®Œæ•´åˆ—è¡¨)' if len(candidate_files) > 5 else '')}

**ğŸ“Š åˆ†æè¯¦æƒ…:**
- ğŸ” æ ¹æ®Issueæè¿°è¿›è¡Œè¯­ä¹‰åˆ†æ
- ğŸ“‚ æ‰«æé¡¹ç›®ç»“æ„å’Œæ–‡ä»¶ä¾èµ–å…³ç³»  
- ğŸ¯ åŒ¹é…æ½œåœ¨çš„é—®é¢˜ä»£ç ä½ç½®
- ğŸ“ ç”Ÿæˆè¯¦ç»†è¯Šæ–­æŠ¥å‘Š

**ğŸ“‹ ç”Ÿæˆæ–‡ä»¶:** `agent/analysis.md`
**ğŸ”— å·¥ä½œåˆ†æ”¯:** `{job['branch']}`

---
*æ¥ä¸‹æ¥å°†åŸºäºè¿™äº›æ–‡ä»¶åˆ¶å®šä¿®å¤æ–¹æ¡ˆ...*"""
        
        return {
            'success': True,
            'candidate_files': candidate_files,
            'comment': comment,
            'stage_data': {
                'analysis_method': 'LLM' if not demo_files else 'demo',
                'confidence_level': 'high' if len(candidate_files) <= 5 else 'medium',
                'files_analyzed': len(file_list) if not demo_files else 0
            }
        }
        
    except Exception as e:
        logger.error(f"Locate stage failed: {e}", exc_info=True)
        return {
            'success': False,
            'error': str(e)
        }

def find_candidate_files(job: Dict[str, Any], repo_path: str) -> List[str]:
    """Find candidate files using simple heuristics"""
    
    candidates = []
    
    # Look for common source directories
    common_paths = ['src/', 'lib/', 'app/', '']
    common_extensions = ['.py', '.js', '.ts', '.java', '.cpp', '.c', '.go', '.rs', '.php']
    
    for base_path in common_paths:
        full_path = os.path.join(repo_path, base_path)
        if os.path.exists(full_path):
            # Find source files
            for root, dirs, files in os.walk(full_path):
                # Skip hidden directories and common ignore patterns
                dirs[:] = [d for d in dirs if not d.startswith('.') and d not in ['node_modules', '__pycache__', 'target', 'build']]
                
                for file in files[:5]:  # Limit to first 5 files per directory
                    if any(file.endswith(ext) for ext in common_extensions):
                        rel_path = os.path.relpath(os.path.join(root, file), repo_path)
                        candidates.append(rel_path)
                        
                        if len(candidates) >= 3:  # Max 3 candidates for demo
                            break
                
                if len(candidates) >= 3:
                    break
            
            if len(candidates) >= 3:
                break
    
    # Fallback: look for README and common config files
    if not candidates:
        fallback_files = ['README.md', 'README.rst', 'README.txt', 'package.json', 'setup.py', 'Makefile']
        for file in fallback_files:
            file_path = os.path.join(repo_path, file)
            if os.path.exists(file_path):
                candidates.append(file)
                if len(candidates) >= 2:
                    break
    
    # Final fallback
    if not candidates:
        candidates = ['README.md', 'src/main.py', 'app.py']
    
    return candidates

def get_repository_files(repo_path: str) -> List[str]:
    """Get list of all relevant files in the repository for LLM analysis"""
    
    files = []
    ignore_dirs = {'.git', '__pycache__', 'node_modules', '.pytest_cache', 'build', 'dist', 'target'}
    ignore_exts = {'.pyc', '.pyo', '.log', '.tmp', '.cache', '.DS_Store'}
    
    try:
        for root, dirs, filenames in os.walk(repo_path):
            # Filter out ignored directories
            dirs[:] = [d for d in dirs if d not in ignore_dirs and not d.startswith('.')]
            
            for filename in filenames:
                # Skip ignored files
                if any(filename.endswith(ext) for ext in ignore_exts):
                    continue
                if filename.startswith('.'):
                    continue
                    
                rel_path = os.path.relpath(os.path.join(root, filename), repo_path)
                files.append(rel_path)
                
                # Limit total files to avoid token limits
                if len(files) >= 200:
                    break
            
            if len(files) >= 200:
                break
                
    except Exception as e:
        logger.warning(f"Error scanning repository: {e}")
    
    return files

def render_analysis_with_llm(issue_title: str, issue_body: str, candidate_files: List[str], 
                           llm_analysis: Dict[str, Any]) -> str:
    """Render analysis.md with detailed LLM insights"""
    
    analysis_summary = llm_analysis.get('analysis', 'é€šè¿‡ä»£ç ç»“æ„åˆ†æè¯†åˆ«ç›¸å…³æ–‡ä»¶')
    technical_areas = llm_analysis.get('technical_areas', ['ä»£ç é€»è¾‘', 'åŠŸèƒ½å®ç°'])
    reasoning = llm_analysis.get('reasoning', 'åŸºäºæ–‡ä»¶åå’Œé¡¹ç›®ç»“æ„çš„åˆ†æ')
    
    content = f"""# é—®é¢˜å®šä½åˆ†ææŠ¥å‘Š

## ğŸ“‹ é—®é¢˜æ¦‚è¿°
**æ ‡é¢˜:** {issue_title}
**æè¿°:** {issue_body if issue_body else 'è¯¦ç»†æè¿°è¯·å‚è€ƒåŸå§‹Issue'}

## ğŸ¯ æ ¹å› åˆ†æ
{analysis_summary}

## ğŸ”§ æ¶‰åŠæŠ€æœ¯é¢†åŸŸ
{chr(10).join(f'- **{area}**: å¯èƒ½éœ€è¦æ£€æŸ¥ç›¸å…³çš„å®ç°é€»è¾‘å’Œé…ç½®' for area in technical_areas)}

## ğŸ“‚ å€™é€‰é—®é¢˜æ–‡ä»¶

åŸºäºé—®é¢˜æè¿°å’Œä»£ç ç»“æ„åˆ†æï¼Œè¯†åˆ«å‡ºä»¥ä¸‹æ–‡ä»¶æœ€å¯èƒ½åŒ…å«ç›¸å…³é—®é¢˜ï¼š

{chr(10).join(f'''### `{file_path}`
- **ç›¸å…³æ€§**: é«˜åº¦ç›¸å…³
- **æ£€æŸ¥é‡ç‚¹**: æŸ¥çœ‹æ ¸å¿ƒé€»è¾‘å®ç°ã€é”™è¯¯å¤„ç†å’Œè¾¹ç•Œæ¡ä»¶
- **ä¿®å¤ä¼˜å…ˆçº§**: å»ºè®®ä¼˜å…ˆæ£€æŸ¥æ­¤æ–‡ä»¶çš„ç›¸å…³åŠŸèƒ½''' for file_path in candidate_files)}

## ğŸ’¡ åˆ†æä¾æ®
{reasoning}

## ğŸ” æ¨èä¿®å¤ç­–ç•¥
åŸºäºå½“å‰åˆ†æï¼Œå»ºè®®é‡‡ç”¨ä»¥ä¸‹ä¿®å¤ç­–ç•¥ï¼š
1. é‡ç‚¹æ£€æŸ¥ä¸Šè¿°å€™é€‰æ–‡ä»¶çš„ç›¸å…³åŠŸèƒ½å®ç°
2. åˆ†æé—®é¢˜çš„æ ¹æœ¬åŸå› å’Œè§¦å‘æ¡ä»¶
3. åˆ¶å®šå‘åå…¼å®¹çš„ä¿®å¤æ–¹æ¡ˆ
4. ç¡®ä¿ä¿®å¤ä¸ä¼šå¼•å…¥æ–°çš„é—®é¢˜

---
*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')} UTC*
*åˆ†ææ–¹æ³•: LLM + å¯å‘å¼ç®—æ³•*
"""
    
    return content
